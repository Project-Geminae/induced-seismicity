#!/usr/bin/env python3
# swd_data_import.py â€” filter statewide SWD data to wells inside the Midland Basin
#                     and show summary statistics before / after that spatial cut.

import os                                     # std-lib: path utilities
import sys                                    # std-lib: exit and platform info
from datetime import datetime                 # std-lib: for date demo (not used, kept for parity)

import pandas as pd                           # 3rd-party: fast table manipulation

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FILES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FILENAME = "swd_data.csv"                     # raw input file (daily injection records, statewide)
OUTFILE  = "swd_data_filtered.csv"            # output limited to Midland Basin records

# Columns we must retain for later geospatial or causal work
KEEP_COLS = [
    "API Number",
    "Date of Injection",
    "Volume Injected (BBLs)",
    "Injection Pressure Average PSIG",
    "Injection Pressure Max PSIG",
    "Surface Longitude",
    "Surface Latitude",
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SPATIAL BOUNDING BOX (WGS-84) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Rough rectangle around the Midland Basin (used to discard far-away wells)
MIN_LAT, MAX_LAT = 30.6, 33.4                # south â€¦ north
MIN_LON, MAX_LON = -103.2, -100.2            # west  â€¦ east
# ----------------------------------------------------------------------

def quick_stats(df: pd.DataFrame, tag: str) -> None:
    """
    Emit a one-shot summary of key metrics for the supplied DataFrame.

    Parameters
    ----------
    df  : DataFrame with SWD injection rows
    tag : Short label for the console header (â€œBEFORE â€¦â€ / â€œAFTER â€¦â€)
    """
    row_cnt   = len(df)                                    # total rows
    well_cnt  = df["API Number"].nunique()                 # distinct wells
    date_min  = df["Date of Injection"].min()              # earliest injection
    date_max  = df["Date of Injection"].max()              # latest injection
    vol_sum   = df["Volume Injected (BBLs)"].sum()         # total barrel count
    press_avg = df["Injection Pressure Average PSIG"].mean()  # mean pressure

    # Pretty print the summary block
    print(f"\nğŸ“ˆ  {tag} â€” summary")
    print(f"   Rows .................... {row_cnt:,}")
    print(f"   Unique wells (API) ...... {well_cnt:,}")
    print(f"   Date range .............. {date_min} â†’ {date_max}")
    print(f"   Total injected (BBL) .... {vol_sum:,.0f}")
    print(f"   Mean avg pressure (PSI).. {press_avg:,.1f}")

def main() -> None:
    """Pipeline entry-point."""
    # 1 â”€â”€ Load CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not os.path.isfile(FILENAME):                       # guard: file must exist
        print(f"âŒ  '{FILENAME}' not found in {os.getcwd()}")  # explicit path in error
        sys.exit(1)

    try:
        df = pd.read_csv(FILENAME, low_memory=False)       # load entire table
    except Exception as exc:
        print(f"âŒ  Could not read '{FILENAME}': {exc}")    # print root cause
        sys.exit(1)

    # 2 â”€â”€ Validate column presence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    missing = [c for c in KEEP_COLS if c not in df.columns]
    if missing:                                            # abort if any critical column is absent
        print(f"âŒ  Missing column(s): {missing}")
        sys.exit(1)

    # 3 â”€â”€ Clean & subset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df = df[KEEP_COLS].copy()                              # keep only the columns we care about

    # Convert lat/lon strings to numerics; coerce bad rows to NaN (theyâ€™ll be dropped)
    lat_col, lon_col = "Surface Latitude", "Surface Longitude"
    df[lat_col] = pd.to_numeric(df[lat_col], errors="coerce")
    df[lon_col] = pd.to_numeric(df[lon_col], errors="coerce")

    # Drop rows with missing / zero coordinates (0,0 is an obvious bad marker)
    df = df.dropna(subset=[lat_col, lon_col])
    df = df[(df[lat_col] != 0) & (df[lon_col] != 0)]

    # 4 â”€â”€ Show stats BEFORE spatial cut â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    quick_stats(df, "BEFORE bounding-box filter")

    # 5 â”€â”€ Apply Midland-Basin bounding box â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    lat_mask = df[lat_col].between(MIN_LAT, MAX_LAT, inclusive="both")
    lon_mask = df[lon_col].between(MIN_LON, MAX_LON, inclusive="both")
    df_filtered = df[lat_mask & lon_mask]                  # keep only rows inside the bbox

    # 6 â”€â”€ Stats AFTER spatial cut â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    quick_stats(df_filtered, "AFTER  bounding-box filter")

    # 7 â”€â”€ Quick preview + save to disk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ”  First 5 wells INSIDE the Midland Basin:\n")
    print(df_filtered.head())

    df_filtered.to_csv(OUTFILE, index=False)               # write filtered CSV
    print(f"\nğŸ’¾  Filtered data saved â†’ {OUTFILE} ({len(df_filtered):,} rows)")

# Bootstrapped main runner
if __name__ == "__main__":
    main()